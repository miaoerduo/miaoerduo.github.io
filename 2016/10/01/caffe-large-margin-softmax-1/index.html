<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    基于Caffe的Large Margin Softmax Loss的实现（一） |
    
    喵耳朵</title>
  
  <link rel="shortcut icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<script src="/js/pace.min.js"></script>

  <link href="https://cdn.bootcdn.net/ajax/libs/firacode/5.2.0/fira_code.min.css" rel="stylesheet">
  <link href="https://cdn.bootcdn.net/ajax/libs/prism/1.24.1/themes/prism-okaidia.min.css" rel="stylesheet">
  <link href="https://cdn.bootcdn.net/ajax/libs/prism/1.24.1/plugins/line-numbers/prism-line-numbers.css" rel="stylesheet">
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="喵耳朵" type="application/atom+xml">
</head>

<body>
  <main class="content">
    <section class="outer">
  <article id="post-caffe-large-margin-softmax-1" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
      

<h1 class="article-title" itemprop="name">
  基于Caffe的Large Margin Softmax Loss的实现（一）
</h1>



    </header>
    

    
    <div class="article-meta">
      <a href="/2016/10/01/caffe-large-margin-softmax-1/" class="article-date">
  <time datetime="2016-10-01T16:09:42.000Z" itemprop="datePublished">2016-10-01</time>
</a>
      
<div class="article-category">
  <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a>
</div>

      <div class="wordcount wordcount-num">2.4k 字</div>
      <div class="wordcount wordcount-time">大约需要 11 分钟</div>
    </div>
    

    
    
<div class="tocbot"></div>

    

    <div class="article-entry" itemprop="articleBody">
      
      
      
      <blockquote>
<p>小喵的唠叨话：在写完上一次的博客之后，已经过去了2个月的时间，小喵在此期间，做了大量的实验工作，最终在使用的DeepID2的方法之后，取得了很不错的结果。这次呢，主要讲述一个比较新的论文中的方法，L-Softmax，据说单model在LFW上能达到98.71%的等错误率。更重要的是，小喵觉得这个方法和DeepID2并不冲突，如果二者可以互补，或许单model达到99%+将不是梦想。</p>
</blockquote>
<span id="more"></span>
<p>和上一篇博客一样，小喵对读者做了如下的假定：</p>
<ol type="1">
<li>了解Deep Learning的基本知识。</li>
<li>仔细阅读过L-Softmax的论文，了解其中的数学推导。</li>
<li>使用Caffe作为训练框架。</li>
<li>即使不满足上述3条，也能持之以恒的学习。</li>
</ol>
<p>L-Softmax的论文：Large-Margin Softmax Loss for Convolutional Neutral Networks Google 一下，第一条应该就是论文的地址，鉴于大家时间有限，小喵把原文地址也贴出来了，但不保证长期有效。<a target="_blank" rel="noopener" href="http://jmlr.org/proceedings/papers/v48/liud16.pdf">http://jmlr.org/proceedings/papers/v48/liud16.pdf</a> 这里我们也将整个系列分几部分来讲。</p>
<h2 id="一margin与lambda">一、margin与lambda</h2>
<p>margin和lambda这两个参数是我们这篇博客的重点。也是整篇论文的重点。对于分类的任务，每个样本都会有N的输出的分数（N的类别），如果在训练中，人为的使正确类别的得分变小，也就是说加大了区分正确类别的难度，那么网络就会学习出更有区分能力的特征，并且加大类间的距离。作者选用的加大难度的方式就是改变最后一个FC层中的weight和特征之间的角度值，角度增大的倍数就是margin，从而使特定类别的得分变小。而第二个参数lambda是为了避免网络不收敛而设定的，我们之后会讲到。</p>
<p>为了实现这个效果，我们需要设计一个新的层，<code>large_margin_inner_product_layer</code>。这个层和一般的 <code>inner_product_layer</code> 很相似，但是多了特定类别削弱的功能。</p>
<p>考虑到这个层是有参数的，我们需要在 <code>caffe.proto</code>（<code>caffe_home/src/caffe/proto/caffe.proto</code>）中做一些修改。这里的定义是按照 <code>protobuf</code> 的语法写的，简单的修改只要照着其他的参数来改写就好。</p>
<p>首先定义我们的这个层的参数。</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">message LargeMarginInnerProductParameter &#123;
  optional uint32 num_output = 1; // The number of outputs for the layer
  optional bool bias_term = 2 [default = true]; // whether to have bias terms
  optional FillerParameter weight_filler = 3; // The filler for the weight
  optional FillerParameter bias_filler = 4; // The filler for the bias

  // The first axis to be lumped into a single inner product computation;
  // all preceding axes are retained in the output.
  // May be negative to index from the end (e.g., -1 for the last axis).
  optional int32 axis = 5 [default = 1];
  // Specify whether to transpose the weight matrix or not.
  // If transpose == true, any operations will be performed on the transpose
  // of the weight matrix. The weight matrix itself is not going to be transposed
  // but rather the transfer flag of operations will be toggled accordingly.
  optional bool transpose = 6 [default = false];
  optional uint32 margin = 7 [default = 1];
  optional float lambda = 8 [default = 0];
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>参数的定义和 <code>InnerProductParameter</code> 非常相似，只是多了两个参数 <code>margin</code> 和 <code>lambda</code>。</p>
<p>之后在 <code>LayerParameter</code> 添加一个可选参数（照着 <code>InnerProductParameter</code> 写就好）。</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">optional LargeMarginInnerProductParameter large_margin_inner_product_param = 147;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这时，喵粉可能很在意这个147是怎么回事。其实呢，在protobuf中，每个结构中的变量都需要一个id，只要保证不重复即可。我们在LayerParameter的最开始可以看到这么一行注释：</p>
<p><img src="next-availabel-layer-id.jpg" alt="next-availabel-layer-id" /></p>
<p>说明下一个有效的id是147。这里我们新加的参数就果断占用了这个id。修改之后，建议把注释改一下（不要人为的挖坑）：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">LayerParameter next available layer-specific ID: 148 (last added: large_margin_inner_product_param)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>避免之后再新加层的时候出问题。 工作完毕，我们就可以在 <code>train_val.prototxt</code> 中用这种方式使用这个新层了（具体的使用，后面再说）：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">layer &#123;
  name: "fc2"
  type: "LargeMarginInnerProduct"
  bottom: "fc1"
  bottom: "label"
  top: "fc2"
  param &#123;
    lr_mult: 1
    decay_mult: 1
  &#125;
  param &#123;
    lr_mult: 0
    decay_mult: 0
  &#125;
  large_margin_inner_product_param &#123;
    num_output: 10000
    margin: 2
    lambda: 0
    weight_filler &#123;
      type: "xavier"
    &#125;
  &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="二运筹帷幄之成员变量">二，运筹帷幄之成员变量</h2>
<p>我们刚刚在 <code>caffe.proto</code> 中，添加了新参数的定义。而事实上，我们还没有这个层的具体实现。这部分，主要介绍我们需要的临时变量。</p>
<p>首先，我们要理清整个计算的流程。</p>
<p>先看前馈。</p>
<p>第一步，需要求出W和x的夹角的余弦值：</p>
<p><span class="math display">\[
cos(\theta_j)=\frac{W_j^Tx_i}{\|W_j\|\|x_i\|} 
\]</span></p>
<p>第二步，计算m倍角度的余弦值：</p>
<p><span class="math display">\[
\cos(m\theta_i)=\sum_n(-1)^n{C_m^{2n}\cos^{m-2n}(\theta_i)\cdot(1-\cos(\theta_i)^2)^n}, (2n\leq m)
\]</span></p>
<p>第三步，计算前馈：</p>
<p><span class="math display">\[
f_{y_{i}}=(-1)^k\cdot\|W_{y_{i}}\|\|x_{i}\|\cos(m\theta_i)-2k\cdot\|W_{y_i}\|\|x_i\|
\]</span></p>
<p>k是根据 <span class="math inline">\(\cos(\theta)\)</span> 的取值决定的。</p>
<p>后馈比前馈要复杂一些，不过使用的变量也是一样的。因此我们可以编写自己的头文件了。</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifndef</span> <span class="token expression">CAFFE_LARGE_MARGIN_INNER_PRODUCT_LAYER_HPP_</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">CAFFE_LARGE_MARGIN_INNER_PRODUCT_LAYER_HPP_</span></span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;vector></span></span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"caffe/blob.hpp"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"caffe/layer.hpp"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"caffe/proto/caffe.pb.h"</span></span>

<span class="token keyword">namespace</span> caffe <span class="token punctuation">&#123;</span>

<span class="token keyword">template</span> <span class="token operator">&lt;</span><span class="token keyword">typename</span> <span class="token class-name">Dtype</span><span class="token operator">></span>
<span class="token keyword">class</span> <span class="token class-name">LargeMarginInnerProductLayer</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">Layer</span><span class="token operator">&lt;</span><span class="token class-name">Dtype</span><span class="token operator">></span></span> <span class="token punctuation">&#123;</span>
 <span class="token keyword">public</span><span class="token operator">:</span>
  <span class="token keyword">explicit</span> <span class="token function">LargeMarginInnerProductLayer</span><span class="token punctuation">(</span><span class="token keyword">const</span> LayerParameter<span class="token operator">&amp;</span> param<span class="token punctuation">)</span>
      <span class="token operator">:</span> <span class="token generic-function"><span class="token function">Layer</span><span class="token generic class-name"><span class="token operator">&lt;</span>Dtype<span class="token operator">></span></span></span><span class="token punctuation">(</span>param<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
  <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">LayerSetUp</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">Reshape</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">virtual</span> <span class="token keyword">inline</span> <span class="token keyword">const</span> <span class="token keyword">char</span><span class="token operator">*</span> <span class="token function">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">const</span> <span class="token punctuation">&#123;</span> <span class="token keyword">return</span> <span class="token string">"LargeMarginInnerProduct"</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>
  <span class="token comment">// edited by miao</span>
  <span class="token comment">// LM_FC层有两个bottom</span>
  <span class="token keyword">virtual</span> <span class="token keyword">inline</span> <span class="token keyword">int</span> <span class="token function">ExactNumBottomBlobs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">const</span> <span class="token punctuation">&#123;</span> <span class="token keyword">return</span> <span class="token number">2</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>
  <span class="token comment">// end edited</span>
  <span class="token keyword">virtual</span> <span class="token keyword">inline</span> <span class="token keyword">int</span> <span class="token function">ExactNumTopBlobs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">const</span> <span class="token punctuation">&#123;</span> <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>

 <span class="token keyword">protected</span><span class="token operator">:</span>
  <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">Forward_cpu</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">Forward_gpu</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">Backward_cpu</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span><span class="token keyword">bool</span><span class="token operator">></span><span class="token operator">&amp;</span> propagate_down<span class="token punctuation">,</span> <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">Backward_gpu</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span><span class="token keyword">bool</span><span class="token operator">></span><span class="token operator">&amp;</span> propagate_down<span class="token punctuation">,</span> <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">int</span> M_<span class="token punctuation">;</span>
  <span class="token keyword">int</span> K_<span class="token punctuation">;</span>
  <span class="token keyword">int</span> N_<span class="token punctuation">;</span>
  <span class="token keyword">bool</span> bias_term_<span class="token punctuation">;</span>
  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> bias_multiplier_<span class="token punctuation">;</span>
  <span class="token keyword">bool</span> transpose_<span class="token punctuation">;</span>  <span class="token comment">///&lt; if true, assume transposed weights</span>

  <span class="token comment">// added by miao</span>

  <span class="token comment">// 一些常数</span>
  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> cos_theta_bound_<span class="token punctuation">;</span>   <span class="token comment">// 区间边界的cos值</span>
  Blob<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> k_<span class="token punctuation">;</span>                   <span class="token comment">// 当前角度theta所在的区间的位置</span>
  Blob<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> C_M_N_<span class="token punctuation">;</span>               <span class="token comment">// 组合数</span>
  <span class="token keyword">unsigned</span> <span class="token keyword">int</span> margin<span class="token punctuation">;</span>            <span class="token comment">// margin</span>
  <span class="token keyword">float</span> lambda<span class="token punctuation">;</span>                   <span class="token comment">// lambda</span>

  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> wx_<span class="token punctuation">;</span>                <span class="token comment">// wjT * xi</span>
  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> abs_w_<span class="token punctuation">;</span>             <span class="token comment">// ||wj||</span>
  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> abs_x_<span class="token punctuation">;</span>             <span class="token comment">// ||xi||</span>
  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> cos_t_<span class="token punctuation">;</span>             <span class="token comment">// cos(theta)</span>
  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> cos_mt_<span class="token punctuation">;</span>            <span class="token comment">// cos(margin * theta)</span>

  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> dydw_<span class="token punctuation">;</span>              <span class="token comment">// 输出对w的导数</span>
  Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> dydx_<span class="token punctuation">;</span>              <span class="token comment">// 输出对x的导数</span>
  <span class="token comment">// end added</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">;</span>

<span class="token punctuation">&#125;</span>  <span class="token comment">// namespace caffe</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span>  <span class="token comment">// CAFFE_LARGE_MARGIN_INNER_PRODUCT_LAYER_HPP_</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里主要是复制了 <code>inner_product_layer.hpp</code>，然后做了一点修改。具体是增加了几个成员变量，同时改了 <code>ExactNumBottomBlobs</code> 的返回值，因为我们的这个层磁带 <code>bottom</code> 需要两个，前一层的 <code>feature</code> 和样本的 <code>label</code>。</p>
<h2 id="三内存和常量的初始化">三、内存和常量的初始化</h2>
<p>这部分，主要给我们的各个成员变量分配内存，同时给几个常量进行初始化。这里也是照着 <code>inner_product_layer.cpp</code> 来写的，在 <code>setup</code> 的时候，增加了一些用于初始化的代码，并删除了 <code>forward_cpu</code> 和 <code>backwark_cpu</code> 的具体实现。</p>
<p>修改之后的代码如下：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;vector></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cmath></span></span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"caffe/filler.hpp"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"caffe/layers/large_margin_inner_product_layer.hpp"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"caffe/util/math_functions.hpp"</span></span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PI</span> <span class="token expression"><span class="token number">3.14159265</span></span></span>

<span class="token keyword">namespace</span> caffe <span class="token punctuation">&#123;</span>

<span class="token keyword">int</span> <span class="token function">factorial</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token number">0</span> <span class="token operator">==</span> n<span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span>
  <span class="token keyword">int</span> f <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
  <span class="token keyword">while</span> <span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    f <span class="token operator">*=</span> n<span class="token punctuation">;</span>
    <span class="token operator">--</span> n<span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
  <span class="token keyword">return</span> f<span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">template</span> <span class="token operator">&lt;</span><span class="token keyword">typename</span> <span class="token class-name">Dtype</span><span class="token operator">></span>
<span class="token keyword">void</span> <span class="token class-name">LargeMarginInnerProductLayer</span><span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token double-colon punctuation">::</span><span class="token function">LayerSetUp</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

  <span class="token keyword">const</span> <span class="token keyword">int</span> axis <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">CanonicalAxisIndex</span><span class="token punctuation">(</span>
      <span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_margin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">axis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token comment">// added by miao</span>
  std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">wx_shape</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  wx_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">shape</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>wx_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>wx_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>abs_w_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>wx_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>abs_x_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>wx_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>k_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>wx_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>cos_t_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>wx_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>cos_mt_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>wx_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>

  std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">cos_theta_bound_shape</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>margin <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_margin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">margin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  cos_theta_bound_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-></span>margin <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>cos_theta_bound_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>cos_theta_bound_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> k <span class="token operator">&lt;=</span> <span class="token keyword">this</span><span class="token operator">-></span>margin<span class="token punctuation">;</span> <span class="token operator">++</span> k<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">this</span><span class="token operator">-></span>cos_theta_bound_<span class="token punctuation">.</span><span class="token function">mutable_cpu_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token function">cos</span><span class="token punctuation">(</span>PI <span class="token operator">*</span> k <span class="token operator">/</span> <span class="token keyword">this</span><span class="token operator">-></span>margin<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>C_M_N_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>cos_theta_bound_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> n <span class="token operator">&lt;=</span> <span class="token keyword">this</span><span class="token operator">-></span>margin<span class="token punctuation">;</span> <span class="token operator">++</span> n<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">this</span><span class="token operator">-></span>C_M_N_<span class="token punctuation">.</span><span class="token function">mutable_cpu_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">factorial</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-></span>margin<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token function">factorial</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-></span>margin <span class="token operator">-</span> n<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token function">factorial</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">// d size</span>
  std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">d_shape</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  d_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">shape</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  d_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">count</span><span class="token punctuation">(</span>axis<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>dydw_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>d_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">this</span><span class="token operator">-></span>dydx_<span class="token punctuation">.</span><span class="token function">Reshape</span><span class="token punctuation">(</span>d_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">this</span><span class="token operator">-></span>lambda <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_margin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">lambda</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token comment">// end added</span>

  transpose_ <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span> <span class="token comment">// 坚决不转置！</span>

  <span class="token keyword">const</span> <span class="token keyword">int</span> num_output <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_margin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">num_output</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  bias_term_ <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_marin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">bias_term</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  N_ <span class="token operator">=</span> num_output<span class="token punctuation">;</span>
  
  <span class="token comment">// Dimensions starting from "axis" are "flattened" into a single</span>
  <span class="token comment">// length K_ vector. For example, if bottom[0]'s shape is (N, C, H, W),</span>
  <span class="token comment">// and axis == 1, N inner products with dimension CHW are performed.</span>
  K_ <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">count</span><span class="token punctuation">(</span>axis<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token comment">// Check if we need to set up the weights</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"Skipping parameter initialization"</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>bias_term_<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">.</span><span class="token function">resize</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">.</span><span class="token function">resize</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token comment">// Initialize the weights</span>
    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">weight_shape</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>transpose_<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      weight_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> K_<span class="token punctuation">;</span>
      weight_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> N_<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
      weight_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> N_<span class="token punctuation">;</span>
      weight_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> K_<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">reset</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token generic-function"><span class="token function">Blob</span><span class="token generic class-name"><span class="token operator">&lt;</span>Dtype<span class="token operator">></span></span></span><span class="token punctuation">(</span>weight_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// fill the weights</span>
    shared_ptr<span class="token operator">&lt;</span>Filler<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> <span class="token operator">></span> <span class="token function">weight_filler</span><span class="token punctuation">(</span><span class="token generic-function"><span class="token function">GetFiller</span><span class="token generic class-name"><span class="token operator">&lt;</span>Dtype<span class="token operator">></span></span></span><span class="token punctuation">(</span>
        <span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_margin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">weight_filler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    weight_filler<span class="token operator">-></span><span class="token function">Fill</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// If necessary, intiialize and fill the bias term</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>bias_term_<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">bias_shape</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> N_<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">reset</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token generic-function"><span class="token function">Blob</span><span class="token generic class-name"><span class="token operator">&lt;</span>Dtype<span class="token operator">></span></span></span><span class="token punctuation">(</span>bias_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      shared_ptr<span class="token operator">&lt;</span>Filler<span class="token operator">&lt;</span>Dtype<span class="token operator">></span> <span class="token operator">></span> <span class="token function">bias_filler</span><span class="token punctuation">(</span><span class="token generic-function"><span class="token function">GetFiller</span><span class="token generic class-name"><span class="token operator">&lt;</span>Dtype<span class="token operator">></span></span></span><span class="token punctuation">(</span>
          <span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_margin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">bias_filler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      bias_filler<span class="token operator">-></span><span class="token function">Fill</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>   

  <span class="token punctuation">&#125;</span>  <span class="token comment">// parameter initialization</span>
  <span class="token keyword">this</span><span class="token operator">-></span>param_propagate_down_<span class="token punctuation">.</span><span class="token function">resize</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-></span>blobs_<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">template</span> <span class="token operator">&lt;</span><span class="token keyword">typename</span> <span class="token class-name">Dtype</span><span class="token operator">></span>
<span class="token keyword">void</span> <span class="token class-name">LargeMarginInnerProductLayer</span><span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token double-colon punctuation">::</span><span class="token function">Reshape</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">,</span>
      <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// Figure out the dimensions</span>
  <span class="token keyword">const</span> <span class="token keyword">int</span> axis <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">CanonicalAxisIndex</span><span class="token punctuation">(</span>
      <span class="token keyword">this</span><span class="token operator">-></span>layer_param_<span class="token punctuation">.</span><span class="token function">large_margin_inner_product_param</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">axis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">const</span> <span class="token keyword">int</span> new_K <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">count</span><span class="token punctuation">(</span>axis<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">CHECK_EQ</span><span class="token punctuation">(</span>K_<span class="token punctuation">,</span> new_K<span class="token punctuation">)</span>
      <span class="token operator">&lt;&lt;</span> <span class="token string">"Input size incompatible with large margin inner product parameters."</span><span class="token punctuation">;</span>
  <span class="token comment">// The first "axis" dimensions are independent inner products; the total</span>
  <span class="token comment">// number of these is M_, the product over these dimensions.</span>
  M_ <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">count</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> axis<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token comment">// The top shape will be the bottom shape with the flattened axes dropped,</span>
  <span class="token comment">// and replaced by a single axis with dimension num_output (N_).</span>
  vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> top_shape <span class="token operator">=</span> bottom<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">shape</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  top_shape<span class="token punctuation">.</span><span class="token function">resize</span><span class="token punctuation">(</span>axis <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  top_shape<span class="token punctuation">[</span>axis<span class="token punctuation">]</span> <span class="token operator">=</span> N_<span class="token punctuation">;</span>
  top<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token function">Reshape</span><span class="token punctuation">(</span>top_shape<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">template</span> <span class="token operator">&lt;</span><span class="token keyword">typename</span> <span class="token class-name">Dtype</span><span class="token operator">></span>
<span class="token keyword">void</span> <span class="token class-name">LargeMarginInnerProductLayer</span><span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token double-colon punctuation">::</span><span class="token function">Forward_cpu</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">,</span>
    <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// not implement</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">template</span> <span class="token operator">&lt;</span><span class="token keyword">typename</span> <span class="token class-name">Dtype</span><span class="token operator">></span>
<span class="token keyword">void</span> <span class="token class-name">LargeMarginInnerProductLayer</span><span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token double-colon punctuation">::</span><span class="token function">Backward_cpu</span><span class="token punctuation">(</span><span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> top<span class="token punctuation">,</span>
    <span class="token keyword">const</span> vector<span class="token operator">&lt;</span><span class="token keyword">bool</span><span class="token operator">></span><span class="token operator">&amp;</span> propagate_down<span class="token punctuation">,</span>
    <span class="token keyword">const</span> vector<span class="token operator">&lt;</span>Blob<span class="token operator">&lt;</span>Dtype<span class="token operator">></span><span class="token operator">*</span><span class="token operator">></span><span class="token operator">&amp;</span> bottom<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// not implement</span>
<span class="token punctuation">&#125;</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifdef</span> <span class="token expression">CPU_ONLY</span></span>
<span class="token function">STUB_GPU</span><span class="token punctuation">(</span>LargeMarginInnerProductLayer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span>

<span class="token function">INSTANTIATE_CLASS</span><span class="token punctuation">(</span>LargeMarginInnerProductLayer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">REGISTER_LAYER_CLASS</span><span class="token punctuation">(</span>LargeMarginInnerProduct<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token punctuation">&#125;</span>  <span class="token comment">// namespace caffe</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>至此，<code>large_margin_inner_product_layer</code> 的准备工作就做完了。</p>
<p>下一篇博客，我们来详细的讨论前馈的具体实现。</p>
<p>如果您觉得本文对您有帮助，</p>
<p><strong>转载</strong> 请注明出处~</p>

      
    </div>
    <footer class="article-footer">
      
        <div>
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>
        作者: 
      </strong>
      Zhao Yu</a>
    </li>
    <li class="post-copyright-link">
      <strong>
        文章链接: 
      </strong>
      <a href="/2016/10/01/caffe-large-margin-softmax-1/" target="_blank" title="基于Caffe的Large Margin Softmax Loss的实现（一）">
        https://www.miaoerduo.com/2016/10/01/caffe-large-margin-softmax-1/
      </a>
    </li>
    <li class="post-copyright-license">
      <strong>
        版权声明: 
      </strong>
      本网站所有文章除特别声明外,均采用 <a rel="license"
          href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh-Hans" target="_blank"
          title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-SA 4.0)">CC BY-SA 4.0</a>
        许可协议。转载请注明出处!
    </li>
  </ul>
<div>
      
      
      
    </footer>

  </div>

  
  
<nav class="article-nav">
  
  <a href="/2016/10/08/caffe-large-margin-softmax-2/" class="article-nav-link">
    <strong class="article-nav-caption">前一篇</strong>
    <div class="article-nav-title">
      
      基于Caffe的Large Margin Softmax Loss的实现（二）
      
    </div>
  </a>
  
  
  <a href="/2016/07/15/deepid2-3/" class="article-nav-link">
    <strong class="article-nav-caption">后一篇</strong>
    <div class="article-nav-title">基于Caffe的DeepID2实现（下）</div>
  </a>
  
</nav>

  

  
  
<div class="vcomments" id="vcomments"></div>

<script src="https://unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  new Valine({
    el: '#vcomments',
    appId: 'mABH5OG3C2B5Ix9WzfF7vjiE-gzGzoHsz',
    appKey: 'EObjAwnwQdyltsmlS48XLJ19',
    notify: 'true',
    verify: 'true',
    avatar: 'mp',
    pageSize: '10',
    placeholder: '请输入...'
  })
</script>

  
  

</article>
  
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
    });
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  
</section>
    <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>喵耳朵 &copy; 2025</li>
      
        <li><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" class="beian">京ICP备16004318号-1</a></li>
      
    </ul>
  </div>
</footer>
  </main>
  <aside class="sidebar">
    <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/MED-logo-black.png" alt="喵耳朵"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">首页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories/Architecture">架构</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories/Illustration">插画</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="搜索">
        <i class="fe fe-search"></i>
        搜索
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="fe fe-feed"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
  </aside>
  
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>



<script src="/fancybox/jquery.fancybox.min.js"></script>






<script src="/js/tocbot.min.js"></script>

<script>
  // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
  });
</script>



<script src="/js/ocean.js"></script>

</body>

</html>